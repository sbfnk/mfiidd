<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>MCMC diagnostics</title>

<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-6.4.0/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.4.0/css/v4-shims.min.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="mfiidd.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">MFIIDD 2023</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="introduction.html">Introduction</a>
</li>
<li>
  <a href="mcmc.html">MCMC</a>
</li>
<li>
  <a href="mcmc_diagnostics.html">Diagnostics</a>
</li>
<li>
  <a href="play_with_seitl.html">Modelling interlude</a>
</li>
<li>
  <a href="mcmc_and_model_comparison.html">Model comparison</a>
</li>
<li>
  <a href="pmcmc.html">Particle MCMC</a>
</li>
<li>
  <a href="ABC.html">ABC</a>
</li>
<li>
  <a href="further_methods.html">Further methods</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="contact.html">
    <span class="fa fa-envelope-o"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/sbfnk/mfiidd">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">MCMC diagnostics</h1>

</div>


<p><a href="slides/mcmc_slides2.pdf">Lecture slides</a></p>
<div id="objectives" class="section level1">
<h1>Objectives</h1>
<p>The aim of this session is to learn how to interpret the results of MCMC sampling, as well as to improve the performance of the sampler. More specifically, you will</p>
<ol style="list-style-type: decimal">
<li>use MCMC to sample more than one parameter</li>
<li>learn how to use <code>coda</code> for assessing and interpreting MCMC runs</li>
<li>explore strategies for improving the performance of a Metropolis-Hastings sampler</li>
</ol>
</div>
<div id="sampling-more-than-one-parameter" class="section level1">
<h1>Sampling more than one parameter</h1>
<p>If we are fitting more than one parameter, it can be beneficial to use a multivariate proposal distribution such as the multivariate Gaussian. We have included a function called <code>mcmcMh</code>in the <code>fitR</code> package which is built on the Metropolis-Hastings sampler of the last session but extends it to a scenario of multiple parameters by replacing the univariate Gaussian proposal distribution of <code>my_mcmcMh</code> with a multivariate Gaussian, using the <code>rtmvtnorm</code> from the <code>tmvtnorm</code> package. In fact, the <code>rtmvtnorm</code> function calculates the probability density of a vector under a <em>truncated</em> multivariate Gaussian, that is one that can have boundaries. We will get back to this issue later.</p>
<p>The <code>mcmcMh</code> takes the same parameters as the <code>my_mcmcMh</code> function you used in the previous practical session and can be used the same way, but it also allows to specify a covariance matrix (via the <code>covmat</code> parameter) instead of <code>proposalSd</code>. For now, we will keep using <code>proposalSd</code> but pass it a named vector of standard deviations, e.g. <code>proposalSd = c(R_0 = 1, D_inf = 2)</code>, in which case the sampler will use independent normal draws for the proposal distribution with standard deviation 1 and 2, respectively.</p>
<p>As a running example, we are going to analyse the data set <code>epi3</code>, which was generated from an SIR model with unknown basic reproduction number <span class="math inline">\(R_0\)</span> and infectious period <span class="math inline">\(D_\mathrm{inf}\)</span>.</p>
<p>You can visualise the <code>epi3</code> data set with</p>
<pre class="r"><code>plotTraj(data = epi3)</code></pre>
<p><img src="figure/mcmc_diagnostics/epi3_traj-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>The first step is to write a wrapper for the log-posterior similar to <code>my_dLogPosteriorR0Epi1</code> but for more than one parameter and using the data set <code>epi3</code> – if you have trouble with that, you can use our <a href="epi3_wrapper.html">solution</a>.</p>
<p><strong>Once you have your wrapper, use the <code>mcmcMh</code> function with parameters <code>target</code>, <code>initTheta</code>, <code>proposalSd</code> and <code>nIterations</code> to sample from the posterior distribution. Take 15 minutes to sample from the joint posterior of <span class="math inline">\(R_0\)</span> and <span class="math inline">\(D_\mathrm{inf}\)</span>. In particular, try a few values for the vector of standard deviations <code>proposalSd</code> and see how this affects the acceptance rate.</strong></p>
<p>You should notice that getting the acceptance rate to a desired value is harder when dealing with multiple parameters. Actually, there are a few strategies available for doing so, which we will learn about in this practical session.</p>
<p>For instance, if you experience a very low or a very high acceptance rate, it is a good idea to first consider each parameter individually, and tweak the corresponding standard deviation of the proposal until a desired acceptance rate is achieved. Once this is done, you can start exploring multiple parameters at once, and carefully adjust the proposal steps to get good acceptance rates. Later, we will look at a way to automatically adapt the proposal steps on the basis of the samples taken so far.</p>
</div>
<div id="diagnostics" class="section level1">
<h1>Diagnostics</h1>
<p>Whenever one runs MCMC, it is important to assess its performance. It is very difficult (arguably, impossible) to be fully sure that a particular set of MCMC runs provides reliable analysis, but, fortunately, there are ways to spot when things go wrong. We will look at assessing three aspects of MCMC: mixing, burn-in and run length</p>
<p>We will use functions from the <strong>R</strong> package <code>coda</code> to diagnose MCMC runs. <strong>We suggest that, once you’ve read this section, you spend a good half hour experimenting with the Metropolis-Hastings sampler and the <code>coda</code> package. Take your time to fully understand the behaviour of the Metropolis-Hastings sampler – this is what we will use throughout this course.</strong> Don’t only try to get the best fit – it is also worth experimenting with what you need to do to break the sampler, i.e. get results inconsistent with what you found before. You could try to see if this happens when starting set from different initial values, with different values for the step size (<code>proposalSd</code>), and assess the impact on the summary statistics and plots introduced below. Similarly, you could experiment with the burn-in and thinning (which we will introduce below), and see what impact they have.</p>
<div id="summary-statistics" class="section level2">
<h2>Summary statistics</h2>
<p>Diagnosing MCMC usually implies a graphical assessment of the behaviour of the sampler with respect to each fitted parameter, as well as of some summary statistics, and <code>coda</code> provides a rich suite of functions to this end. We suggest that you use the commands below to assess MCMC runs with different values of the initial parameters <code>initTheta</code> and step size <code>proposalSd</code>. If you didn’t get an MCMC run to work, you can look at the output of an MCMC run that we did for you and saved in the <code>mcmcEpi3</code> object, which you can load with <code>data(mcmcEpi)</code>:</p>
<pre class="r"><code>data(mcmcEpi)
head(mcmcEpi3)</code></pre>
<pre><code>##          R_0    D_inf
## [1,] 1.00000 2.000000
## [2,] 1.00036 1.996335
## [3,] 1.00036 1.996335
## [4,] 1.01127 2.031932
## [5,] 1.01127 2.031932
## [6,] 1.01127 2.031932</code></pre>
<p>This run was created using the commands shown <a href="mcmc_commands.html">here</a>. In the following, we assume that you assigned the result of <code>my_mcmcMh</code> to a variable called <code>trace</code>, but of course you can call this anything you like.</p>
<p>To use <code>coda</code>, we must first convert our trace to a format that <code>coda</code> understands. To this end, we use the <code>mcmc</code> function from that package:</p>
<pre class="r"><code>library(&quot;coda&quot;)
mcmcTrace &lt;- mcmc(mcmcEpi3)</code></pre>
<p>We can get summary statics using <code>summary</code></p>
<pre class="r"><code>summary(mcmcTrace)</code></pre>
<pre><code>## 
## Iterations = 1:10001
## Thinning interval = 1 
## Number of chains = 1 
## Sample size per chain = 10001 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##        Mean     SD Naive SE Time-series SE
## R_0   2.016 0.1042 0.001042        0.01965
## D_inf 2.989 0.1835 0.001835        0.03967
## 
## 2. Quantiles for each variable:
## 
##        2.5%   25%   50%   75% 97.5%
## R_0   1.796 2.019 2.032 2.046 2.071
## D_inf 2.565 2.987 3.016 3.046 3.099</code></pre>
<p>This provides the following information:</p>
<ol style="list-style-type: decimal">
<li>Empirical (sample) mean</li>
<li>Empirical (sample) standard deviation</li>
<li>“Naive” standard error, that is the <a href="http://en.wikipedia.org/wiki/Standard_error#Standard_error_of_the_mean">standard error of the mean</a> (adjusting for sample size).</li>
<li>Time-series standard error, which corrects the “naive” standard error for autocorrelations</li>
<li>Quantiles for each variable</li>
</ol>
<p>We can also compute the acceptance rate (that is 1 minus the rejection rate).</p>
<pre class="r"><code>acceptanceRate &lt;- 1 - rejectionRate(mcmcTrace)
acceptanceRate</code></pre>
<pre><code>##    R_0  D_inf 
## 0.2168 0.2168</code></pre>
<p>Lastly, we can compute the effective sample size, that is an estimate for the number of <em>independent</em> samples (taking into account autocorrelations) generated by the MCMC run.</p>
<pre class="r"><code>effectiveSize(mcmcTrace)</code></pre>
<pre><code>##      R_0    D_inf 
## 28.14071 21.39217</code></pre>
</div>
<div id="mixing" class="section level2">
<h2>Mixing</h2>
<p>We need to make sure that the MCMC sampler explores the parameter space <em>efficiently</em>, that is that it doesn’t reject or accept too many proposals. If too many proposals are rejected, we need many simulations to generate a sufficient number of parameter samples. If too many proposals are accepted, we don’t gain much information about the underlying distribution.</p>
<div id="trace-and-density-plots" class="section level3">
<h3>Trace and density plots</h3>
<p>Trace plots provide an important tool for assessing mixing of a chain. Density plots are smoothed histograms of the samples, that is they show the function that we are trying to explore. We can get trace and density plots for all variables in an MCMC trace using <code>plot</code>.</p>
<pre class="r"><code>plot(mcmcTrace)</code></pre>
<p><img src="figure/mcmc_diagnostics/trace-1.png" width="960" style="display: block; margin: auto;" /></p>
<p><em>NB: the “bandwidth” indicated is automatically selected by the function to smooth the density plots.</em></p>
<p>In the trace plots, we want to try to avoid flat bits (where the chain stays in the same state for too long) or too many consecutive steps in one direction. In this case, it looks like there was a burn-in of about 1000 iterations, after which the MCMC sampler seems to mix well.</p>
<p>We also see that the sampler never moves beyond 2.2 for <span class="math inline">\(R_0\)</span>, and never beyond 3.5 for <span class="math inline">\(D_\mathrm{inf}\)</span>. To assess the reliability of our output, we should start chains with higher initial values of <span class="math inline">\(R_0\)</span> and <span class="math inline">\(D_\mathrm{inf}\)</span> and check that the sampler converges to the same estimates.</p>
<p>If we want to get a more detailed view of the posterior distribution (i.e., the density of the samples) around its maximum, we can cut the burn-in period out using the <code>burnAndThin</code> (this function is part of the <code>fitR</code> package but returns objects compatible with <code>coda</code> functions):</p>
<pre class="r"><code>mcmcTraceBurned &lt;- burnAndThin(mcmcTrace, burn = 1000)
plot(mcmcTraceBurned)</code></pre>
<p><img src="figure/mcmc_diagnostics/trace_burned-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>It is sometimes said that we are aiming for the trace to look like a <a href="external_fig/import/hairy_caterpillar.jpg">hairy caterpillar</a>. Can you see the resemblance to the plots on the left?</p>
</div>
<div id="autocorrelations" class="section level3">
<h3>Autocorrelations</h3>
<p>Another way to check for convergence is to look at the autocorrelations between the samples returned by our MCMC. The lag-<span class="math inline">\(k\)</span> autocorrelation is the correlation between every sample and the sample <span class="math inline">\(k\)</span> steps before. This autocorrelation should become smaller as <span class="math inline">\(k\)</span> increases, i.e. samples can be considered as independent. If, on the other hand, autocorrelation remains high for higher values of <span class="math inline">\(k\)</span>, this indicates a high degree of correlation between our samples and slow mixing.</p>
<pre class="r"><code>autocorr.plot(mcmcTraceBurned)</code></pre>
<p><img src="figure/mcmc_diagnostics/autocorrelations-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>In this case, the autocorrelation drops with increasing <span class="math inline">\(k\)</span> (or “lag”, the x-axis in the plot), which is a good sign. If autocorrelation persists, we can <em>thin</em> the MCMC chain, that is we discard <span class="math inline">\(n\)</span> samples for every sample that we keep. To do this, again we use <code>burnAndThin</code> and pass the number of samples <span class="math inline">\(n\)</span> to be discarded for each kept sample as <code>thin</code> argument:</p>
<pre class="r"><code>mcmcTraceBurnedThinned &lt;- burnAndThin(mcmcTraceBurned, thin = 5)
autocorr.plot(mcmcTraceBurnedThinned)</code></pre>
<p><img src="figure/mcmc_diagnostics/trace_burned_thinned-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>It has been argued that thinning is actually not very useful, unless one wants to reduce the amount of memory and storage space in long chains. Instead of thinning to, say, keep only 1 out every 10 samples, it is usually more efficient (in terms of the effective sample size) to just run a chain 10 times as long, but it will take 10 times more storage space.</p>
</div>
</div>
<div id="burn-in" class="section level2">
<h2>Burn-in</h2>
<p>In the above example, we assessed burn-in based on a glance at the trace plots. There are several diagnostics available to make this process more systematic, such as the Geweke diagnostic (<code>geweke.diag</code>), the Heidelberger-Welch diagnostic (<code>heidel.diag</code>), and the Raftery-Lewis diagnostic (<code>raftery.diag</code>). A discussion of these is beyond the scope and purpose of this session, but if you are interested have a look at the <strong>R</strong> help pages for these functions (using <code>?geweke.diag</code> etc.) and the reference <a href="#going-further">below</a> for more information.</p>
<p>A better estimate for burn-in cut-off is via the effective sample size (ESS), that is the number of independent samples equivalent to our number of autocorrelated samples. The samples in the burn-in are not very informative, and if the burn-in period is estimated to be too short this will reduce the ESS size. On the other hand, if the burn-in period is estimated to be too long, informative samples are being thrown away, again reducing the ESS. The ESS should be maximised at the optimal estimate of the burn-in.</p>
<p>We can plot ESS against burn-in:</p>
<pre class="r"><code>plotEssBurn(mcmcTrace)</code></pre>
<p><img src="figure/mcmc_diagnostics/test_burn_in-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>A good optimal burn-in length would be when the ESS has hit its maximum for all parameters, that is at around 500 here.</p>
</div>
<div id="run-length" class="section level2">
<h2>Run length</h2>
<p>It is usually difficult to tell for how long one should run the chain. If the trace of all parameters shows the “caterpillar”-like behaviour such as shown above, it is a good indication that the MCMC is efficiently sampling from a maximum in the underlying distribution, but the sampler might be stuck in a <em>local</em> maximum, and it might need more time to leave that maximum and reach other parts of the parameter space, with potentially other maxima.</p>
<p>There are no general rules for how long one needs to run the chain, but generally it is a good idea to start the chain from different starting points and make sure they converge to the same density plots. In fact, it is good practice to <em>always</em> run multiple chains. Secondly, one can decide in advance on the number of samples one wants from the underlying distribution, and run the chain until the effective sample size reaches that number. In practice, however, this is a somewhat arbitrary decision, and apart from careful diagnosis and running multiple chains there is not much one can do to get a reliable estimate of the necessary number of iterations.</p>
</div>
</div>
<div id="improving-mixing" class="section level1">
<h1>Improving mixing</h1>
<p>Getting an MCMC sampler to mix well is, arguably, the most difficult and most important task for using it efficiently. We will discuss two ways for improving mixing: dealing with parameters with limited support and adaptive MCMC.</p>
<div id="dealing-with-parameters-with-limited-support" class="section level2">
<h2>Dealing with parameters with limited support</h2>
<p>Often, we have situations where parameters are constrained to remain between certain values. For example, negative values do not make sense for the basic reproduction number <span class="math inline">\(R_0\)</span> or the duration of infection <span class="math inline">\(D_\mathrm{inf}\)</span>, and probabilities have to stay between 0 and 1. We call the values that a parameter can, <em>in principle</em>, take the <em>support</em> of a parameter. This is different from the prior distribution which encodes our prior knowledge of likely values of a parameter among the values it can take.</p>
<p>If we ignore the limited support that parameters can have, we might waste MCMC steps, for example when the random draw from the proposal distribution suggests a step to a negative value of a parameter with positive support (e.g., <span class="math inline">\(R_0\)</span>). In this case, proposals are rejected not because the parameter fails to match the data, but because they are in <em>impossible</em> parts of the parameter space.</p>
<div id="transforming-parameters" class="section level3">
<h3>Transforming parameters</h3>
<p>A first way for dealing with parameters with limited support applies mostly to parameters which are limited to be positive, as is often the case for <em>rates</em>, such as the ones in the SIR model. A way to force a parameter to be positive is to <em>transform</em> them to the log-scale, that is to run MCMC on <span class="math inline">\(\log{(R_0)}\)</span> instead of <span class="math inline">\(R_0\)</span>. When calculating the model, we can use the exponential function to transform the parameter back.</p>
<p>An SIR model where the parameters are defined on the log-scale is contained in the <code>sirExpDeter</code> object that can be loaded with <code>data(models)</code>.</p>
<p>You can, again, use a wrapper function and use MCMC to explore the parameters.</p>
<pre class="r"><code>my_dLogPosteriorExpEpi3 &lt;- function(theta) {
  return(my_dLogPosterior(
    fitmodel = sirExpDeter,
    theta = theta,
    initState = c(S = 999, I = 1, R = 0),
    data = epi3
  ))
}

trace &lt;- my_mcmcMh(
  target = my_dLogPosteriorExpEpi3,
  initTheta = c(R_0 = log(1), D_inf = log(2)),
  proposalSd = c(0.1, 0.01),
  nIterations = 1000
)</code></pre>
<p><strong>Take 10 minutes to check whether this makes a difference to acceptance rates?</strong></p>
</div>
<div id="truncated-proposal-distributions" class="section level3">
<h3>Truncated proposal distributions</h3>
<p>Another way for dealing with parameters with limited support is to use <em>truncated</em> proposal distributions. There are <strong>R</strong> packages for truncated normal and multivariate normal distributions – these never draw proposals outside of specified limits. However, the use of such truncated distributions in the proposal kernel must be accounted for when computing the acceptance ratio. Otherwise your chain might not converge to the correct posterior distribution (look at this excellent <a href="http://darrenjw.wordpress.com/tag/truncate/">post</a> by Darren Wilkinson for a detailed example).</p>
<p>The <code>mcmcMh</code> function implemented in the <code>fitR</code> package uses the truncated multivariate normal random generator from the <code>tmvtnorm</code> package to draw proposals. Of course the function accounts for this asymmetric proposal to calculate the acceptance ratio. The limits of the support of the proposal distribution can be specified with the <code>limits</code> argument to <code>mcmcMh</code>, in which you can specified <code>lower</code> and/or <code>upper</code> limits. For example, to get a lower bound of 0 for <span class="math inline">\(R_0\)</span> and <span class="math inline">\(D_\mathrm{inf}\)</span>, we could write</p>
<pre class="r"><code>my_dLogPosteriorEpi3 &lt;- function(theta) {
  return(my_dLogPosterior(
    fitmodel = sirDeter,
    theta = theta,
    initState = c(S = 999, I = 1, R = 0),
    data = epi3
  ))
}</code></pre>
<pre class="r"><code>trace &lt;- mcmcMh(
  target = my_dLogPosteriorEpi3,
  initTheta = c(R_0 = 1, D_inf = 2),
  proposalSd = c(0.1, 0.01),
  nIterations = 10000,
  limits = list(lower = c(R_0 = 0, D_inf = 0))
)</code></pre>
<p><strong>Take 10 minutes to try a proposal distribution with a wide proposal distribution, and with or without limits. Do the limits make a difference to the acceptance rate?</strong></p>
</div>
</div>
<div id="adapting-the-proposal-distribution" class="section level2">
<h2>Adapting the proposal distribution</h2>
<p>The best proposal distribution is the one that best matches the target distribution. While we cannot know this in advance, we can use trial MCMC runs to learn about the target distribution, and use this information to come up with a better proposal distribution. This does mean, however, that we waste computational time in the discarded trial runs, and this method needs to be applied carefully.</p>
<p>In addition to truncated proposal distributions, our function <code>mcmcMh</code> also implements some adaptive features. In particular, it calculates the <em>empirical</em> covariance matrix, that is the covariance matrix as it appears from the distribution of accepted proposals. This is returned as <code>covmat.empirical</code>:</p>
<pre class="r"><code>trace$covmatEmpirical</code></pre>
<pre><code>##              R_0      D_inf
## R_0   0.00948875 0.02201203
## D_inf 0.02201203 0.05279508</code></pre>
<p>The diagonal elements of this matrix tell you about the typical variance of accepted steps and thus gives you an indication of an appropriate step size. The off-diagonal elements tell you about <em>correlations</em> in the parameters. In this case, there is positive correlation between <span class="math inline">\(R_0\)</span> and <span class="math inline">\(D_\mathrm{inf}\)</span>, that is greater values of <span class="math inline">\(R_0\)</span> in accepted proposals tend to coincide with greater values of <span class="math inline">\(D_\mathrm{inf}\)</span>. <strong>Can you think of why that is the case?</strong> We will come back to the issue of correlations and their impact on assessing model fits tomorrow.</p>
<p>Instead of manually adjusting the proposal distribution as we have done so far, we can automate this process. If this is done carefully, the samples generated by the MCMC converge to the correct distribution. We have implemented this in the <code>mcmcMh</code> function. This takes three parameters relating to adaptive MCMC: <code>adaptive.size.start</code>, <code>adaptive.shape.start</code> and <code>adapt.size.cooling</code>.</p>
<p>The idea is the following: we let the MCMC run for a while and monitor the acceptance rate. After <code>adapt.size.start</code> iterations, we start adapting the <em>size</em> of the proposal distribution, that is we scale it to smaller/larger steps depending if the acceptance is too small/large. This is done until <code>adapt.shape.start</code> proposals have been accepted, at which point we take the empirical covariance matrix and start adapting the <em>shape</em> of the proposal distribution to it. Over time, we must make fewer and fewer changes to the size, because if we kept adapting the size we would break the Metropolis-Hastings algorithm. This is regulated by <code>adapt.size.cooling</code>. The closer this is to 1, the slower we stop adapting the size (and, accordingly, the longer we have to run the chain).</p>
<p>Try a run of adaptive MCMC using</p>
<pre class="r"><code>trace &lt;- mcmcMh(
  target = my_dLogPosteriorEpi3,
  initTheta = c(R_0 = 1, D_inf = 2),
  proposalSd = c(1, 0.5),
  nIterations = 5000,
  adaptSizeStart = 100,
  adaptShapeStart = 500,
  adaptSizeCooling = 0.999,
  limits = list(lower = c(R_0 = 0, D_inf = 0))
)</code></pre>
<p>Don’t worry if you see warnings – this could be due to numerical errors in the ODE solver of <code>deSolve</code>, which can lead to negative data points, which in turn produces <code>NaN</code>s ("Not a Number) when evaluating the likelihood.</p>
<p><strong>Take note of the acceptance rate when the adaptive sampler starts adapting the size first, and then the shape. Have a look at the trace plots (see above) and the effect that adaptation has. Does it work in ensuring good mixing?</strong></p>
</div>
</div>
<div id="going-further" class="section level1">
<h1>Going further</h1>
<p>To read more about MCMC diagnostics, have a look at Cowles &amp; Carlin’s excellent <a href="external_ref/Cowles96_MCMCconvergence.pdf">review</a>.</p>
<p>You can also try to fit a model with reporting to the <code>epi4</code> data set. This is a model with 3 parameters (the basic reproduction number <span class="math inline">\(R_0\)</span>, the infectious period <span class="math inline">\(D_\mathrm{inf}\)</span> and the reporting rate <span class="math inline">\(RR\)</span>) and is contained in the <code>sirReporting</code> object loaded with <code>data(models)</code>.</p>
<p>Have a look at the point observation probability density function</p>
<pre class="r"><code>sirReporting$dPointObs</code></pre>
<p>Can you fit this to the <code>epi4</code> data set?</p>
</div>

&nbsp;
<hr />
<p>This web site and the material contained in it were originally created in support of an annual
  short course
  on <a href="https://www.lshtm.ac.uk/study/courses/short-courses/infectious-diseases-dynamics">
  Model Fitting and Inference for Infectious Disease Dynamics</a> at
  the <a href="https://www.lshtm.ac.uk/">London School of Hygiene & Tropical
  Medicine</a>. All material is under
  a <a href="https://github.com/sbfnk/mfiidd/blob/main/LICENSE">MIT
  license</a>. Please report any issues or suggestions for improvement on the
  corresponding <a href="https://github.com/sbfnk/mfiidd/issues">GitHub
  issue tracker</a>. We are always keen to hear about any uses of the material
  here, so please do get in touch using the <a href="https://github.com/sbfnk/mfiidd/discussions">Discussion
  board</a> if you have any questions
  or ideas, or if you find the material here useful or use it in your own
  teaching.
</p>

&nbsp;<script data-goatcounter="https://mfiidd.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
