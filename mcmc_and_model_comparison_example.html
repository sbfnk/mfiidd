<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Example: fitting the deterministic SEITL model</title>

<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-6.4.0/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.4.0/css/v4-shims.min.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="mfiidd.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">MFIIDD 2023</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="introduction.html">Introduction</a>
</li>
<li>
  <a href="mcmc.html">MCMC</a>
</li>
<li>
  <a href="mcmc_diagnostics.html">Diagnostics</a>
</li>
<li>
  <a href="play_with_seitl.html">Modelling interlude</a>
</li>
<li>
  <a href="mcmc_and_model_comparison.html">Model comparison</a>
</li>
<li>
  <a href="pmcmc.html">Particle MCMC</a>
</li>
<li>
  <a href="ABC.html">ABC</a>
</li>
<li>
  <a href="further_methods.html">Further methods</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="contact.html">
    <span class="fa fa-envelope-o"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/sbfnk/mfiidd">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Example: fitting the deterministic SEITL model</h1>

</div>


<p>Here is an example of possible answers to the practical on fitting the deterministic SEITL model to the Tristan da Cunha outbreak.</p>
<p>Each section below correspond to a section of the practical. Thus, you can have a look at our example for one section and then go back to the practical to answer the following sections.</p>
<p>Although our example refers to the SEITL model, the same commands work for the SEIT4L model (i.e. <code>seit4lDeter</code> instead of <code>seitlDeter</code>).</p>
<div id="setting-the-mcmc" class="section level1">
<h1>Setting the MCMC</h1>
<pre class="r"><code>knitr::read_chunk(here::here(&quot;scripts&quot;, &quot;snippets&quot;, &quot;set-mcmc.r&quot;))</code></pre>
<p>You can now go back to the <a href="mcmc_and_model_comparison.html#run-a-mcmc">practical</a> and try to run MCMC with those settings.</p>
</div>
<div id="run-mcmc" class="section level1">
<h1>Run MCMC</h1>
<p>If you didn’t manage to run MCMC, or it took too long to obtain a few thousand iterations, you can load our short run as follows:</p>
<pre class="r"><code>data(models)
data(mcmcTdcDeterShortRun)
# this should load 2 objects in your environment: mcmcSeitl and mcmcSeitl4.
# Each one is a list of 3 elements returned by mcmcMh
names(mcmcSeitl)
## [1] &quot;trace&quot;           &quot;acceptanceRate&quot;  &quot;covmatEmpirical&quot;
# the trace contains 9 variables for 5000 iterations
dim(mcmcSeitl$trace)
## [1] 5000    9
# let&#39;s have a look at it
head(mcmcSeitl$trace)
##           R_0    D_lat    D_inf     alpha     D_imm       rho  logPrior
## [1,] 2.392456 2.242859 1.929790 0.7964407 11.960271 0.8082664 -12.81448
## [2,] 2.392456 2.242859 1.929790 0.7964407 11.960271 0.8082664 -12.81448
## [3,] 3.946687 1.910482 2.452853 0.6569316  8.528870 0.6593658 -12.81448
## [4,] 3.946687 1.910482 2.452853 0.6569316  8.528870 0.6593658 -12.81448
## [5,] 5.107992 1.511080 2.425485 0.5822499  6.555264 0.5456772 -12.81448
## [6,] 5.107992 1.511080 2.425485 0.5822499  6.555264 0.5456772 -12.81448
##      logLikelihood logDensity
## [1,]     -434.5553  -447.3698
## [2,]     -434.5553  -447.3698
## [3,]     -320.2052  -333.0197
## [4,]     -320.2052  -333.0197
## [5,]     -195.9429  -208.7574
## [6,]     -195.9429  -208.7574</code></pre>
<p>You can now go back to the <a href="mcmc_and_model_comparison.html#short-run-analysis">practical</a> and analyse this trace.</p>
</div>
<div id="short-run-analysis" class="section level1">
<h1>Short run analysis</h1>
<p>Here is an example of analysis for our preliminary run:</p>
<pre class="r"><code># convert to a mcmc object for coda
library(&quot;coda&quot;)
trace &lt;- mcmc(mcmcSeitl$trace)

# compute the acceptance rate
1 - rejectionRate(trace)
##           R_0         D_lat         D_inf         alpha         D_imm 
##     0.1726345     0.1726345     0.1726345     0.1726345     0.1726345 
##           rho      logPrior logLikelihood    logDensity 
##     0.1726345     0.0000000     0.1726345     0.1726345
# between 0.1 and 0.6: looks good!

# let&#39;s have a look at the traces
library(&quot;lattice&quot;)  ## for the &#39;xyplot&#39; command
xyplot(x = trace)</code></pre>
<p><img src="figure/mcmc_and_model_comparison_example/short-run-analysis-trace-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Although the chain was started at a <code>initTheta</code> with a low posterior density, it quickly finds the region of the parameter space with high posterior density. Note also the constant trace of the log-prior since we have assumed a uniform prior.</p>
<p>Overall, it looks like the chain reached its target distribution after 1000 steps.</p>
<pre class="r"><code># Let&#39;s find a suitable burn-in::
plotEssBurn(trace)</code></pre>
<p><img src="figure/mcmc_and_model_comparison_example/short-run-analysis-burn-test-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>As anticipated from the trace, discarding the first 1000 iterations maximizes the effective sample size (ESS).</p>
<pre class="r"><code># Let&#39;s create a new trace without the burn-in
traceBurn &lt;- burnAndThin(trace, burn = 1000)
xyplot(x = traceBurn)</code></pre>
<p><img src="figure/mcmc_and_model_comparison_example/short-run-analysis-burn-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Let&#39;s check the ESS
effectiveSize(traceBurn)
##           R_0         D_lat         D_inf         alpha         D_imm 
##      70.38059      66.62130      74.02227      84.33808      69.38730 
##           rho      logPrior logLikelihood    logDensity 
##     134.97679       0.00000     100.89045     100.89045</code></pre>
<p>Although we have 4000 samples remaining after burn-in, the ESS is much smaller. This is due to autocorrelation of the chain.</p>
<pre class="r"><code># autocorrelation plot
acfplot(x = traceBurn, lag.max = 60)</code></pre>
<p><img src="figure/mcmc_and_model_comparison_example/short-run-analysis-acf-1.png" width="672" style="display: block; margin: auto;" /> The autocorrelation between samples drops substantially for a lag of 20 iterations. We can thin the trace to reduce the autocorrelation.</p>
<pre class="r"><code># Let&#39;s create a thinned trace
traceBurnThin &lt;- burnAndThin(traceBurn, thin = 20)
xyplot(x = traceBurnThin)</code></pre>
<p><img src="figure/mcmc_and_model_comparison_example/short-run-analysis-thin-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Let&#39;s check the ESS
effectiveSize(traceBurnThin)
##           R_0         D_lat         D_inf         alpha         D_imm 
##      60.32844      56.31209      56.32156      77.34331      62.12285 
##           rho      logPrior logLikelihood    logDensity 
##      96.18594       0.00000      69.92988      69.92988</code></pre>
<p>Although the thinned trace has 20 times less fewer than the unthinned trace, it has a similar ESS. This is because the autocorrelation has been reduced.</p>
<pre class="r"><code># new autocorrelation plot
acfplot(x = traceBurnThin, lag.max = 60)</code></pre>
<p><img src="figure/mcmc_and_model_comparison_example/short-run-analysis-acf-thin-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Let’s compare the posterior estimates of the thinned and unthinned traces.</p>
<pre class="r"><code># The unthinned trace
summary(traceBurn)
## 
## Iterations = 1:4000
## Thinning interval = 1 
## Number of chains = 1 
## Sample size per chain = 4000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##                    Mean      SD  Naive SE Time-series SE
## R_0             15.0775 3.80639 0.0601843       0.453719
## D_lat            1.0115 0.25554 0.0040405       0.031308
## D_inf           10.0611 2.49282 0.0394149       0.289740
## alpha            0.5270 0.04049 0.0006403       0.004409
## D_imm            7.9653 2.13142 0.0337008       0.255876
## rho              0.6866 0.04882 0.0007719       0.004202
## logPrior       -12.8145 0.00000 0.0000000       0.000000
## logLikelihood -141.0424 1.71260 0.0270786       0.170503
## logDensity    -153.8569 1.71260 0.0270786       0.170503
## 
## 2. Quantiles for each variable:
## 
##                    2.5%       25%       50%       75%     97.5%
## R_0              7.6677   12.6097   14.9351   17.6100   22.5097
## D_lat            0.5823    0.8433    0.9635    1.1635    1.5593
## D_inf            4.3501    8.4322   10.1352   11.7960   14.3086
## alpha            0.4339    0.5037    0.5300    0.5541    0.5971
## D_imm            4.3538    6.4310    7.9303    9.0796   12.6237
## rho              0.5886    0.6548    0.6878    0.7179    0.7845
## logPrior       -12.8145  -12.8145  -12.8145  -12.8145  -12.8145
## logLikelihood -145.6333 -141.8981 -140.5947 -139.8680 -138.8092
## logDensity    -158.4478 -154.7126 -153.4091 -152.6825 -151.6237

# The thinned trace
summary(traceBurnThin)
## 
## Iterations = 1:191
## Thinning interval = 1 
## Number of chains = 1 
## Sample size per chain = 191 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##                    Mean      SD Naive SE Time-series SE
## R_0             15.0340 3.67915 0.266214       0.473681
## D_lat            0.9966 0.24756 0.017913       0.032989
## D_inf           10.1004 2.42825 0.175702       0.323560
## alpha            0.5284 0.04102 0.002968       0.004664
## D_imm            7.9954 2.11939 0.153354       0.268897
## rho              0.6882 0.04950 0.003582       0.005048
## logPrior       -12.8145 0.00000 0.000000       0.000000
## logLikelihood -141.0482 1.72186 0.124589       0.205904
## logDensity    -153.8627 1.72186 0.124589       0.205904
## 
## 2. Quantiles for each variable:
## 
##                    2.5%       25%       50%       75%     97.5%
## R_0              7.7944   12.7957   14.8305   17.7131   21.5255
## D_lat            0.5934    0.8350    0.9447    1.1455    1.5276
## D_inf            5.0674    8.5244   10.3264   11.7014   14.2780
## alpha            0.4369    0.5046    0.5279    0.5543    0.6035
## D_imm            4.3360    6.7251    7.9066    9.0377   12.6548
## rho              0.5932    0.6553    0.6877    0.7234    0.7848
## logPrior       -12.8145  -12.8145  -12.8145  -12.8145  -12.8145
## logLikelihood -145.4018 -142.0507 -140.5424 -139.8670 -138.8033
## logDensity    -158.2162 -154.8651 -153.3569 -152.6815 -151.6178</code></pre>
<p>They are very similar. So why thin? Because autocorrelation produces clumpy samples that are unrepresentative, in the short run, of the true underlying posterior distribution. We can check this by comparing the thinned and unthinned distributions using the function <code>plotPosteriorDensity</code> of the <code>fitR</code> package:</p>
<pre class="r"><code>plotPosteriorDensity(list(unthinned = traceBurn, thinned = traceBurnThin))</code></pre>
<p><img src="figure/mcmc_and_model_comparison_example/short-run-analysis-compare-density-1.png" width="960" style="display: block; margin: auto;" /> The thinned trace shows a smoother distribution despite having less samples than the unthinned one. This because the local “bumps” of the unthinned distribution are caused by autocorrelated samples.</p>
<p>You can now go back to the <a href="mcmc_and_model_comparison.html#long-run-analysis">practical</a> and perform a similar analysis for a long-run MCMC.</p>
</div>
<div id="long-run-analysis" class="section level1">
<h1>Long run analysis</h1>
<p>Here is an example of an analysis for our long run (50k iterations)</p>
<pre class="r"><code># load mcmc output
data(mcmcTdcDeterLongRun)

# create mcmc objects for both traces
library(&quot;coda&quot;)
trace1 &lt;- mcmc(mcmcSeitlTheta1$trace)
trace2 &lt;- mcmc(mcmcSeitlTheta2$trace)

# combine traces as mcmc.list object
trace &lt;- mcmc.list(list(trace1, trace2))

# let&#39;s have a look
head(trace, 3)
## [[1]]
## Markov Chain Monte Carlo (MCMC) output:
## Start = 1 
## End = 4 
## Thinning interval = 1 
##           R_0    D_lat    D_inf     alpha    D_imm       rho  logPrior
## [1,] 2.000000 2.000000 2.000000 0.8000000 16.00000 0.8500000 -12.81448
## [2,] 2.000000 2.000000 2.000000 0.8000000 16.00000 0.8500000 -12.81448
## [3,] 1.722749 1.481383 1.186734 0.8390849 11.34142 0.8183184 -12.81448
## [4,] 1.722749 1.481383 1.186734 0.8390849 11.34142 0.8183184 -12.81448
##      logLikelihood logDensity
## [1,]     -445.7795  -458.5939
## [2,]     -445.7795  -458.5939
## [3,]     -421.8376  -434.6520
## [4,]     -421.8376  -434.6520
## 
## [[2]]
## Markov Chain Monte Carlo (MCMC) output:
## Start = 1 
## End = 4 
## Thinning interval = 1 
##           R_0    D_lat    D_inf     alpha    D_imm       rho  logPrior
## [1,] 19.33034 2.075211 1.831636 0.1982534 7.921349 0.3198710 -12.81448
## [2,] 19.33034 2.075211 1.831636 0.1982534 7.921349 0.3198710 -12.81448
## [3,] 19.33034 2.075211 1.831636 0.1982534 7.921349 0.3198710 -12.81448
## [4,] 19.57792 2.405110 3.105701 0.1539486 8.018864 0.3203776 -12.81448
##      logLikelihood logDensity
## [1,]     -295.8436  -308.6581
## [2,]     -295.8436  -308.6581
## [3,]     -295.8436  -308.6581
## [4,]     -261.3233  -274.1378
## 
## attr(,&quot;class&quot;)
## [1] &quot;mcmc.list&quot;

# acceptance rate
1 - rejectionRate(trace)
##           R_0         D_lat         D_inf         alpha         D_imm 
##     0.1954239     0.1954239     0.1954239     0.1954239     0.1954239 
##           rho      logPrior logLikelihood    logDensity 
##     0.1954239     0.0000000     0.1954239     0.1954239
# close to the optimal value of 0.234

# ESS
effectiveSize(trace)
##           R_0         D_lat         D_inf         alpha         D_imm 
##      2556.169      3062.908      2647.090      3281.971      3172.580 
##           rho      logPrior logLikelihood    logDensity 
##      3539.099         0.000      3044.446      3044.446

# plot the traces
library(&quot;lattice&quot;)  ## for the &#39;xyplot&#39; command
xyplot(trace)</code></pre>
<p><img src="figure/mcmc_and_model_comparison_example/long-run-combine-traces-1.png" width="672" style="display: block; margin: auto;" /> Note that the acceptance rate and the ESS are computed for the combined chain whereas the traces are plotted for each chain. Also, given the very high ESS we can reasonably choose a burn-in visually, say 5000 iterations.</p>
<pre class="r"><code>traceBurn &lt;- burnAndThin(trace, burn = 5000)

# removing the burn-in increases the ESS
effectiveSize(traceBurn)
##           R_0         D_lat         D_inf         alpha         D_imm 
##      2495.223      3024.481      3132.444      3201.725      3188.532 
##           rho      logPrior logLikelihood    logDensity 
##      3350.921         0.000      2681.293      2681.293

# autocorrelation
acfplot(traceBurn, lag.max = 60)</code></pre>
<p><img src="figure/mcmc_and_model_comparison_example/long-run-burn-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>Again, given the very high ESS, we can be quite generous in our choice of the thinning.</p>
<pre class="r"><code># Thinning: let&#39;s keep 1 iteration every 40
traceBurnThin &lt;- burnAndThin(traceBurn, thin = 40)
xyplot(traceBurnThin)</code></pre>
<p><img src="figure/mcmc_and_model_comparison_example/long-run-thin-1.png" width="672" style="display: block; margin: auto;" /> However, let’s compare the thinned and unthinnned distributions.</p>
<pre class="r"><code># Note that plotPosteriorDensity can take a list of mcmc.list It will plot the
# different mcmc.list by combining their elements Let&#39;s plot the combined
# unthinned trace vs the combined thinned trace.
plotPosteriorDensity(list(unthinned = traceBurn, thinned = traceBurnThin))</code></pre>
<p><img src="figure/mcmc_and_model_comparison_example/long-run-compare-thin-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>In contrast to the previous short-run, they are almost no difference between the thinned and unthinned chains. <strong>Indeed, with such a long chain, the clumpy autocorrelation has been averaged out!</strong></p>
<p>In fact, there are several references that show that the longer (unthinned) chain usually yields better estimates of the true posterior than the shorter thinned chain, even for percentiles in the tail of the distribution. <strong>That said, thinning can be useful for other reasons, such as memory or time constraints in post-chain processing.</strong></p>
<p>Now, we can compare whether the two independent chains, started at <code>theta1</code> and <code>theta2</code>, have converged to the same posterior distribution</p>
<pre class="r"><code>densityplot(traceBurnThin)</code></pre>
<p><img src="figure/mcmc_and_model_comparison_example/long-run-compare-chains-1.png" width="672" style="display: block; margin: auto;" /> Since the chains have converged to the same posterior, we can use the combined estimates</p>
<pre class="r"><code># the function summary combines the chains of a mcmc.list
summary(traceBurnThin)
## 
## Iterations = 1:1098
## Thinning interval = 1 
## Number of chains = 2 
## Sample size per chain = 1098 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##                    Mean      SD Naive SE Time-series SE
## R_0             17.1056 4.18077 0.089216      0.1006106
## D_lat            1.1431 0.34989 0.007467      0.0083788
## D_inf           10.8010 2.23188 0.047627      0.0501479
## alpha            0.5364 0.03814 0.000814      0.0008609
## D_imm            7.7305 2.20336 0.047019      0.0505641
## rho              0.6958 0.05228 0.001116      0.0011299
## logPrior       -12.8145 0.00000 0.000000      0.0000000
## logLikelihood -141.3144 1.76904 0.037750      0.0428708
## logDensity    -154.1289 1.76904 0.037750      0.0428708
## 
## 2. Quantiles for each variable:
## 
##                    2.5%       25%       50%       75%     97.5%
## R_0             10.1186   14.1379   16.7421   19.7520   26.1080
## D_lat            0.4979    0.8885    1.1353    1.3700    1.8940
## D_inf            6.4580    9.2290   10.8903   12.5063   14.6617
## alpha            0.4595    0.5110    0.5373    0.5622    0.6075
## D_imm            3.8619    6.2249    7.5466    8.9910   12.7175
## rho              0.6002    0.6592    0.6937    0.7321    0.8025
## logPrior       -12.8145  -12.8145  -12.8145  -12.8145  -12.8145
## logLikelihood -145.6336 -142.1916 -140.9629 -140.0194 -138.8614
## logDensity    -158.4481 -155.0061 -153.7774 -152.8339 -151.6759</code></pre>
<p>Running several independent chains starting from different parts of the parameter space allows us to check whether the posterior distribution is multi-modal. If so, then we must be careful when combining the chains. For instance, an estimate of the mean computed with <code>summary</code> won’t be meaningful for a parameter with a multi-modal posterior.</p>
<p><strong>By contrast, for a unimodal posteriors, combining chains is an efficient way to increase the ESS and the precision of the posterior estimates.</strong> Furthermore, running several “shorter” chains in parallel is faster than running one “long” chain.</p>
<p>Finally, let’s assess the fit of the deterministic SEITL model.</p>
<pre class="r"><code># load data
data(fluTdc1971)

# the same initState as for the fit
initState &lt;- c(S = 279, E = 0, I = 2, T = 3, L = 0, Inc = 0)

# by default plotPosteriorFit summarize the fit of 100 thetas sampled from the
# posterior
plotPosteriorFit(trace = trace, fitmodel = seitlDeter, initState = initState, data = fluTdc1971)</code></pre>
<p><img src="figure/mcmc_and_model_comparison_example/long-run-fit-1.png" width="576" style="display: block; margin: auto;" /></p>
<pre class="r"><code>
# alternatively, one can plot the fit of the mean of the posterior (in this
# case the observation is replicated 100 times)
plotPosteriorFit(trace = trace, fitmodel = seitlDeter, initState = initState, data = fluTdc1971,
    posteriorSummary = &quot;mean&quot;)</code></pre>
<p><img src="figure/mcmc_and_model_comparison_example/long-run-fit-2.png" width="576" style="display: block; margin: auto;" /></p>
<pre class="r"><code>
# or using the maximum a posteriori (MAP) estimate
plotPosteriorFit(trace = trace, fitmodel = seitlDeter, initState = initState, data = fluTdc1971,
    posteriorSummary = &quot;max&quot;)</code></pre>
<p><img src="figure/mcmc_and_model_comparison_example/long-run-fit-3.png" width="576" style="display: block; margin: auto;" /></p>
<p>Note that the 95% credible intervals (CI) for the posterior fit under the MAP captures the highest data point. By contrast, the fit of the second peak seems quite poor, even for the MAP.</p>
<p>You can now go back to the <a href="mcmc_and_model_comparison.html#correlations">practical</a> and look at the posterior correlations between the parameters.</p>
</div>
<div id="correlations" class="section level1">
<h1>Correlations</h1>
<p>The correlation of the posterior distribution can be investigated using <code>levelplot</code>.</p>
<pre class="r"><code>library(&quot;lattice&quot;)  ## for the &#39;levelplot command
# levelplot doesn&#39;t accept `mcmc.list`, we pass the first `mcmc` only.
levelplot(traceBurnThin[[1]], col.regions = heat.colors(100))</code></pre>
<p><img src="figure/mcmc_and_model_comparison_example/correlation-levelplot-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Note the strong positive correlations (~0.8) between <span class="math inline">\(R_0\)</span> and <span class="math inline">\(D_{lat}\)</span> and between <span class="math inline">\(R_0\)</span> and <span class="math inline">\(D_{inf}\)</span>. In order to explain the wide 95% CIs of <span class="math inline">\(R_0\)</span> and <span class="math inline">\(D_{inf}\)</span>, let’s have a look at the contact rate <span class="math inline">\(\beta = R_0/D_{inf}\)</span>.</p>
<pre class="r"><code>with(as.data.frame(traceBurnThin[[1]]), quantile(R_0/D_inf, probs = c(0.025, 0.25,
    0.5, 0.75, 0.975)))
##     2.5%      25%      50%      75%    97.5% 
## 1.112567 1.394826 1.584295 1.783682 2.192854</code></pre>
<p>The posterior value of <span class="math inline">\(\beta\)</span> varies somewhat less than the posterior values of <span class="math inline">\(R_0\)</span> and <span class="math inline">\(D_\mathrm{inf}\)</span>. Indeed, this parameter is constrained by the shape of the initial phase of the outbreak. Conversely, there are an infinite number of combinations of <span class="math inline">\(R_0\)</span> and <span class="math inline">\(D_{inf}\)</span> that lead to the same <span class="math inline">\(\beta\)</span>, hence their wide 95% CIs.</p>
<p>A second effect that could explain the wide posterior density in <span class="math inline">\(R_0\)</span> is the very high attack rate. Indeed, once <span class="math inline">\(R_0&gt;5\)</span> it doesn’t make much difference whether <span class="math inline">\(R_0\)</span> is equal to, say, 10 or 20.</p>
<p>We can also note that the posterior estimate of <span class="math inline">\(D_{inf} = 11\)</span> days (95% CI: <span class="math inline">\([6-15]\)</span>) is biologically unrealistic based on previous empirical estimates. However, our approach did not include any prior information as the default <code>seitlDeter</code> fitmodel comes with uniform priors for all parameters.</p>
<p>In order to include previous empirical information on <span class="math inline">\(D_{lat}\)</span> and <span class="math inline">\(D_{inf}\)</span>, let’s modify the <code>dPrior</code> function of <code>seitlDeter</code> as follows:</p>
<pre class="r"><code>seitlDeter$dPrior &lt;- function(theta, log = FALSE) {
    # package with truncated normal distribution
    library(truncnorm)

    logPriorR0 &lt;- dunif(theta[[&quot;R_0&quot;]], min = 1, max = 50, log = TRUE)
    # normal distribution with mean = 2 and sd = 1 and truncated at 0
    logPriorLatentPeriod &lt;- log(dtruncnorm(theta[[&quot;D_lat&quot;]], a = 0, b = Inf, mean = 2,
        sd = 1))
    # normal distribution with mean = 2 and sd = 1 and truncated at 0
    logPriorInfectiousPeriod &lt;- log(dtruncnorm(theta[[&quot;D_inf&quot;]], a = 0, b = Inf,
        mean = 2, sd = 1))
    logPriorTemporaryImmunePeriod &lt;- dunif(theta[[&quot;D_imm&quot;]], min = 0, max = 50, log = TRUE)
    logPriorProbabilityLongTermImmunity &lt;- dunif(theta[[&quot;alpha&quot;]], min = 0, max = 1,
        log = TRUE)
    logPriorReportingRate &lt;- dunif(theta[[&quot;rho&quot;]], min = 0, max = 1, log = TRUE)

    logSum &lt;- logPriorR0 + logPriorLatentPeriod + logPriorInfectiousPeriod + logPriorTemporaryImmunePeriod +
        logPriorProbabilityLongTermImmunity + logPriorReportingRate

    return(ifelse(log, logSum, exp(logSum)))
}</code></pre>
<p>Note the choice of a truncated normal distribution since <span class="math inline">\(D_{lat}\)</span> and <span class="math inline">\(D_{inf}\)</span> must be positive.</p>
<p>You can now go back to the <a href="mcmc_and_model_comparison.html#informative-priors">practical</a> and run a MCMC with this informative prior.</p>
</div>
<div id="informative-priors" class="section level1">
<h1>Informative priors</h1>
<p>Here we combine both chains with informative priors and compare the posterior distribution with the one above.</p>
<pre class="r"><code>library(&quot;coda&quot;)
# create mcmc object
traceInfo1 &lt;- mcmc(mcmcSeitlInfoPriorTheta1$trace)
traceInfo2 &lt;- mcmc(mcmcSeitlInfoPriorTheta2$trace)

# combine in a mcmc.list
traceInfo &lt;- mcmc.list(traceInfo1, traceInfo2)

# burn and thin as the chain with uniform prior (see above sections)
traceInfoBurnThin &lt;- burnAndThin(traceInfo, burn = 5000, thin = 40)

# check that both chains converged to the same posterior
plotPosteriorDensity(traceInfoBurnThin)</code></pre>
<p><img src="figure/mcmc_and_model_comparison_example/info-prior-analysis-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code># compare the effect of informative priors on the posterior distribution
plotPosteriorDensity(list(unif = traceBurnThin, info = traceInfoBurnThin))</code></pre>
<p><img src="figure/mcmc_and_model_comparison_example/info-prior-analysis-2.png" width="672" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(R_0\)</span> and <span class="math inline">\(D_{inf}\)</span> have very different posterior distributions. This is expected as there is an informative prior on <span class="math inline">\(D_{inf}\)</span>, and <span class="math inline">\(R_0\)</span> is strongly correlated to <span class="math inline">\(D_{inf}\)</span>. Note also that the mode of all other parameters have changed, though less than <span class="math inline">\(D_{inf}\)</span> and <span class="math inline">\(R_0\)</span>. This illustrate the influence that one prior can have on the full posterior distribution.</p>
<p>You can now go back to the <a href="mcmc_and_model_comparison.html#model-selection">practical</a>.</p>
</div>
<div id="model-selection" class="section level1">
<h1>Model selection</h1>
<pre class="r"><code># combine the two chains in a data frame
library(&quot;dplyr&quot;)  # needed for the &#39;bind_rows&#39; function
library(&quot;purrr&quot;)  # needed for the &#39;map&#39; function
traceCombined &lt;- bind_rows(purrr::map(traceInfoBurnThin, as.data.frame))

# take the mean of theta
thetaBar &lt;- colMeans(traceCombined[seitlDeter$thetaNames])
print(thetaBar)
##       R_0     D_lat     D_inf     alpha     D_imm       rho 
## 7.6292160 1.2840236 3.6875805 0.4760604 9.1959368 0.6476576

# compute its log-likelihood
initState &lt;- c(S = 279, E = 0, I = 2, T = 3, L = 0, Inc = 0)
logLikeThetaBar &lt;- dTrajObs(seitlDeter, thetaBar, initState, data = fluTdc1971, log = TRUE)
print(logLikeThetaBar)
## [1] -142.7907

# and its deviance
dThetaBar &lt;- -2 * logLikeThetaBar
print(dThetaBar)
## [1] 285.5815

# the effective number of parameters
pD &lt;- var(-2 * traceCombined$logLikelihood)/2
print(pD)
## [1] 8.614696

# and finally the DIC
dic &lt;- dThetaBar + 2 * pD
print(dic)
## [1] 302.8109</code></pre>
<p>Follow this <a href="mcmc_and_model_comparison.html#posterior-predictive-checks">link</a> to go back to the practical.</p>
</div>

&nbsp;
<hr />
<p>This web site and the material contained in it were originally created in support of an annual
  short course
  on <a href="https://www.lshtm.ac.uk/study/courses/short-courses/infectious-diseases-dynamics">
  Model Fitting and Inference for Infectious Disease Dynamics</a> at
  the <a href="https://www.lshtm.ac.uk/">London School of Hygiene & Tropical
  Medicine</a>. All material is under
  a <a href="https://github.com/sbfnk/mfiidd/blob/main/LICENSE">MIT
  license</a>. Please report any issues or suggestions for improvement on the
  corresponding <a href="https://github.com/sbfnk/mfiidd/issues">GitHub
  issue tracker</a>. We are always keen to hear about any uses of the material
  here, so please do get in touch using the <a href="https://github.com/sbfnk/mfiidd/discussions">Discussion
  board</a> if you have any questions
  or ideas, or if you find the material here useful or use it in your own
  teaching.
</p>

&nbsp;<script data-goatcounter="https://mfiidd.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
